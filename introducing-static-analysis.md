## Why Static Analysis

Exercism's biggest barrier is being able to deal with scale. 
Our volunteer-mentors are crucial to Exercism’s success. They are responsible for reviewing learner’s solutions, analysing whether they meet the success criteria of the exercise or need to be improved, empathetically understanding a learner’s thought process, providing encouraging and helpful feedback, and teaching a language’s idioms.
As of today, we are just about managing to keep up with the mentoring demand, but if we want to be able to grow, we need to add solutions other than "add more mentors".

For the Core Exercises that form the spine of an Exercism language track, we estimate that about 25% of submissions are good enough to be marked as complete on a first attempt. A further 55% of submissions have problems that fall into common buckets, which can be mentored by pasting repeatable snippets to a student. Only about 20% of solutions actually require a mentor to be inventive and thoughtful in their feedback. The 80% of solutions that do not truly engage a mentor’s brain are a frustrating and boring time-sink for people who are willing to volunteer their time to helping others, and do not make the most of their expertise.

In parallel to the mentors’ pain-points, depending on the track, learners wait for 1-2 days before receiving feedback on their solution and are unable move forward on the track in the interim. If you fall into the 25% bucket of students who have submitted a perfectly valid solution, this wait is extremely frustrating. To the rest, this delay is suboptimal at best. Learners often lose momentum due to this wait and become frustrated at the process.

To solve this, we intend to develop an automated analysis system that can analyse a solution to understand if: the solution is good enough and can be automatically approved; a simple piece of feedback can be provided to move the learner forward; or the solution requires mentor attention. Our long-term goals is to develop deep-learning algorithms that can analyse the Abstract Syntax Trees (ASTs) of the 930,000 submissions that have been submitted, and detect common patterns and related comments by mentors. Our shorter-term goal is to use Static Analysis of the code to determine what common feedback can be given based on the most commonly repeated errors seen by mentors, and our first step in that is to build a framework for applying Static Analysis to auto-approve good solutions on the first few Core Exercises in the language tracks. We believe we in doing this we can reduce the submission queues by 50%, reduce the feedback cycle for a learner who is getting things mainly right from one day to ten minutes, and eliminate the majority of “boring” work for mentors.
